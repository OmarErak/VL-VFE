{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import argparse\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=False, download=True, transform=transform_test)\n",
    "test_loader_this  = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "def seed_torch(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gamma_layer(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(gamma_layer, self).__init__()\n",
    "        self.H = nn.Parameter(torch.ones(output_channel, input_channel))\n",
    "        self.b = nn.Parameter(torch.ones(output_channel))\n",
    "        self.H.data.normal_(0, 0.1)\n",
    "        self.b.data.normal_(0, 0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        H = torch.abs(self.H)\n",
    "        x = F.linear(x,H)\n",
    "        return torch.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_dim = 64\n",
    "threshold = 0.0001\n",
    "beta = 0.001\n",
    "test_batch_size=1000\n",
    "channel_noise_arg = 0.5\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "gamma = 0.5\n",
    "weights = 'MNIST_model_dim:64_beta:0.001_accuracy:85.7180_model.pth'\n",
    "decay_step = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gamma_function(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(gamma_function, self).__init__()\n",
    "        self.f1 = gamma_layer(1,16)\n",
    "        self.f2 = gamma_layer(16,16)\n",
    "        self.f3 = gamma_layer(16,16)\n",
    "        self.f4 = gamma_layer(16,intermediate_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.f1(x)\n",
    "        x = self.f2(x)\n",
    "        x = self.f3(x)\n",
    "        x = self.f4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduced_labels(target):\n",
    "    # Define the mapping from original labels to reduced labels\n",
    "    reduced_labels = target.clone()\n",
    "    label_mapping = {\n",
    "        0: 0,  # Airplane\n",
    "        1: 1,  # Automobile\n",
    "        2: 2,  # Bird\n",
    "        3: 3,  # Cat\n",
    "        4: 4,  # Deer\n",
    "        5: 3,  # Dog\n",
    "        6: 5,  # Frog\n",
    "        7: 4,  # Horse\n",
    "        8: 0,  # Ship\n",
    "        9: 1   # Truck\n",
    "    }\n",
    "    \n",
    "    for original, reduced in label_mapping.items():\n",
    "        reduced_labels[target == original] = reduced\n",
    "        \n",
    "    return reduced_labels\n",
    "def create_mask_matrix():\n",
    "    mask_matrix = torch.zeros((6, 10))  # 6 reduced labels, 10 final labels\n",
    "    # Define the valid final labels for each reduced label\n",
    "    mask_matrix[0, [0, 8]] = 1  # Reduced label 0 maps to final labels 0 (Airplane) and 8 (Ship)\n",
    "    mask_matrix[1, [1, 9]] = 1  # Reduced label 1 maps to final labels 1 (Automobile) and 9 (Truck)\n",
    "    mask_matrix[2, [2]] = 1     # Reduced label 2 maps to final label 2 (Bird)\n",
    "    mask_matrix[3, [3, 5]] = 1  # Reduced label 3 maps to final labels 3 (Cat) and 5 (Dog)\n",
    "    mask_matrix[4, [4, 7]] = 1  # Reduced label 4 maps to final labels 4 (Deer) and 7 (Horse)\n",
    "    mask_matrix[5, [6]] = 1     # Reduced label 5 maps to final label 6 (Frog)\n",
    "    return mask_matrix\n",
    "\n",
    "mask_matrix = create_mask_matrix().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), x.size(1))\n",
    "\n",
    "class Mul(nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "    def __call__(self, x): \n",
    "        return x*self.weight\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_channel = intermediate_dim\n",
    "        self.mask_matrix = create_mask_matrix().to(device)\n",
    "\n",
    "        self.prep = nn.Sequential(\n",
    "                    nn.Conv2d(3,64,kernel_size = 3,stride = 1, padding = 1, bias = False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU()\n",
    "                    )\n",
    "        self.layer1 = nn.Sequential(\n",
    "                    nn.Conv2d(64,128,kernel_size = 3,stride = 1, padding = 1, bias = False),\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, dilation = 1, ceil_mode = False)\n",
    "                    )\n",
    "        self.layer1_res = nn.Sequential(\n",
    "                    nn.Conv2d(128,128,kernel_size = 3,stride = 1, padding = 1, bias = False),\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(128,128,kernel_size = 3,stride = 1, padding = 1, bias = False),\n",
    "                    nn.BatchNorm2d(128),\n",
    "                    nn.ReLU()\n",
    "                    )\n",
    "        self.layer2 = nn.Sequential(\n",
    "                    nn.Conv2d(128,256,kernel_size = 3,stride = 1, padding = 1, bias = False),\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "                    )\n",
    "        self.layer3 = nn.Sequential(\n",
    "                    nn.Conv2d(256,512,kernel_size = 3,stride = 1, padding = 1, bias = False),\n",
    "                    nn.BatchNorm2d(512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, dilation = 1, ceil_mode = False)\n",
    "                    )\n",
    "        self.layer3_res = nn.Sequential(\n",
    "                    nn.Conv2d(512,512,kernel_size = 3,stride = 1, padding = 1, bias = False),\n",
    "                    nn.BatchNorm2d(512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(512,512,kernel_size = 3,stride = 1, padding = 1, bias = False),\n",
    "                    nn.BatchNorm2d(512),\n",
    "                    nn.ReLU()\n",
    "                    )\n",
    "\n",
    "        self.classifier1 = nn.Sequential(\n",
    "                    nn.MaxPool2d(kernel_size = 4, stride = 4, padding = 0, dilation = 1, ceil_mode = False),\n",
    "                    Flatten()\n",
    "                    )\n",
    "        self.classifier_reduced = nn.Linear(512, 6)  # Reduced classifier\n",
    "        self.classifier_final = nn.Linear(512, 10)  # Final classifier\n",
    "        # self.classifier2 = nn.Sequential(\n",
    "        #             nn.Linear(512,10,bias = False),\n",
    "        #             Mul(0.125)\n",
    "        #             )\n",
    "        \n",
    "        self.encoder1 = nn.Sequential(\n",
    "                        nn.Conv2d(512,4,kernel_size = 3,stride = 1, padding = 1, bias = False),\n",
    "                        nn.BatchNorm2d(4),\n",
    "                        nn.ReLU()\n",
    "                        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "                        nn.Linear(64,64),\n",
    "                        nn.Sigmoid()\n",
    "                        )\n",
    "\n",
    "        self.encoder3_weight = nn.Parameter(torch.Tensor(self.hidden_channel, 64))\n",
    "        self.encoder3_bias = nn.Parameter(torch.Tensor(self.hidden_channel))\n",
    "        self.encoder3_weight.data.normal_(0, 0.5)\n",
    "        self.encoder3_bias.data.normal_(0, 0.1)\n",
    "\n",
    "        self.decoder1 = nn.Linear(self.hidden_channel,64)\n",
    "        self.decoder1_2 = nn.Sequential(\n",
    "                        nn.Linear(64,64),\n",
    "                        nn.ReLU()\n",
    "                        )\n",
    "        self.decoder1_2_2 = nn.Sequential(\n",
    "                        nn.Linear(1,16),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(16,16),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(16,16),\n",
    "                        nn.ReLU()\n",
    "                        )\n",
    "        self.decoder1_3 = nn.Sequential(\n",
    "                        nn.Linear(64+16,64),\n",
    "                        nn.ReLU()\n",
    "                        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "                        nn.Conv2d(4,512,kernel_size = 3,stride = 1, padding = 1, bias = False),\n",
    "                        nn.BatchNorm2d(512),\n",
    "                        nn.ReLU()\n",
    "                        )\n",
    "\n",
    "        self.Tanh = nn.Tanh()\n",
    "        self.gamma_mu = gamma_function().to(device)\n",
    "        self.upper_tri_matrix = torch.triu(torch.ones((intermediate_dim,intermediate_dim))).to(device)\n",
    "\n",
    "    def forward(self, x, epoch, noise = 0.1):\n",
    "\n",
    "        x = self.prep(x)\n",
    "        x = self.layer1(x)\n",
    "        res = self.layer1_res(x)\n",
    "        x = res + x\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.encoder1(x)\n",
    "        x = torch.reshape(x,(x.size()[0],4*4*4))\n",
    "\n",
    "        # Dynamic Channel Conditions\n",
    "        if self.training:\n",
    "            channel_noise = torch.rand(1)*0.27 + 0.05\n",
    "        else:\n",
    "            channel_noise = torch.FloatTensor([1]) * noise\n",
    "        channel_noise = channel_noise.to(device)\n",
    "\n",
    "        x = self.encoder2(x)\n",
    "        x_norm2 = torch.norm(x,dim=1)\n",
    "        x = 64 * (x.permute(1,0)/(x_norm2+1e-6)).permute(1,0)\n",
    "        weight3 = F.tanh(self.encoder3_weight)\n",
    "        bias3 = F.tanh(self.encoder3_bias)\n",
    "        weight3 = torch.clamp(torch.abs(weight3),min = 1e-3) * torch.sign(weight3.detach())\n",
    "        bias3 = torch.clamp(torch.abs(bias3),min = 1e-3) * torch.sign(bias3.detach())\n",
    "        l2_norm_squared = torch.sum(weight3.pow(2),dim = 1) + bias3.pow(2)\n",
    "        l2_norm = l2_norm_squared.pow(0.5)\n",
    "        weight3 = (weight3.permute(1,0) / (l2_norm+1e-6)).permute(1,0)\n",
    "        bias3 = bias3 / (l2_norm+1e-6)\n",
    "        x = F.linear(x, weight3, bias3)\n",
    "\n",
    "        mu = self.gamma_mu(channel_noise)\n",
    "        mu = F.linear(mu, self.upper_tri_matrix)\n",
    "        mu = torch.clamp(mu,min = 1e-4)\n",
    "        encoded_feature = torch.tanh(x * mu)\n",
    "        encoded_feature = torch.clamp(torch.abs(encoded_feature),min = 1e-2) * torch.sign(encoded_feature.detach())\n",
    "        \n",
    "        # KL divergence\n",
    "        KL = self.KL_log_uniform(channel_noise,torch.abs(encoded_feature))\n",
    "\n",
    "        # Gaussian channel noise\n",
    "        x = encoded_feature + torch.randn_like(encoded_feature) * channel_noise\n",
    "\n",
    "        if self.training:\n",
    "            if epoch > 60:\n",
    "                x = x * self.get_mask(mu,threshold = threshold)\n",
    "        else:\n",
    "            x = x * self.get_mask(mu,threshold = threshold)\n",
    "\n",
    "        x = F.relu(self.decoder1(x))\n",
    "        x = self.decoder1_2(x)\n",
    "        noise_feature = self.decoder1_2_2(channel_noise)\n",
    "        noise_feature = noise_feature.expand(x.size()[0],16)\n",
    "        x = torch.cat((x,noise_feature),dim=1)\n",
    "        x = self.decoder1_3(x)\n",
    "        x = torch.reshape(x,(-1,4,4,4))\n",
    "        decoded_feature = self.decoder2(x)\n",
    "        x = self.layer3_res(decoded_feature)\n",
    "        x = x + decoded_feature\n",
    "        x = self.classifier1(x)\n",
    "        output_reduced = self.classifier_reduced(x)\n",
    "        output_final_logits = self.classifier_final(x)\n",
    "        \n",
    "        return F.log_softmax(output_reduced, dim=1), output_final_logits, KL * 0.1 / channel_noise\n",
    "\n",
    "    def KL_log_uniform(self,channel_noise,encoded_feature):\n",
    "\n",
    "        alpha = (channel_noise/encoded_feature)\n",
    "        k1 = 0.63576\n",
    "        k2 = 1.8732\n",
    "        k3 = 1.48695\n",
    "        batch_size = alpha.size(0)\n",
    "        KL_term = k1 * F.sigmoid(k2 + k3 * 2 * torch.log(alpha)) - 0.5 * F.softplus(-2 * torch.log(alpha)) - k1\n",
    "        return - torch.sum(KL_term) / batch_size\n",
    "\n",
    "    def get_mask(self, mu, threshold=threshold):\n",
    "        alpha = mu.detach()\n",
    "        hard_mask = (alpha > threshold).float()\n",
    "        return hard_mask\n",
    "\n",
    "    def get_mask_inference(self, channel_noise, threshold = threshold):\n",
    "        mu = self.gamma_mu(channel_noise)\n",
    "        alpha = F.linear(mu, self.upper_tri_matrix)\n",
    "        hard_mask = (alpha > threshold).float()\n",
    "        return hard_mask, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=decay_step, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def train(model=model):\n",
    "    \n",
    "    test_acc = 0\n",
    "    pruned_dim = 0\n",
    "    saved_model = {}\n",
    "    total_izyreduced = 0\n",
    "    total_izy = 0\n",
    "    total_izx = 0\n",
    "    num_batches = 128\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print('\\nepoch:{}'.format(epoch))\n",
    "        if (epoch) % 10 == 0:\n",
    "            data_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True,\n",
    "                                                      num_workers=4, pin_memory=True)\n",
    "            num_batches = len(data_loader)\n",
    "        for i, (x, y) in enumerate(data_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            model.train()\n",
    "            output_reduced, output_final_logits, KL = model(x, epoch)\n",
    "            \n",
    "            # Get reduced labels\n",
    "            target_reduced = get_reduced_labels(y)\n",
    "            \n",
    "            # Compute the final output based on the reduced label mask\n",
    "            #batch_size = output_final_logits.size(0)\n",
    "            mask = model.mask_matrix[target_reduced]\n",
    "            masked_logits = output_final_logits * mask\n",
    "            \n",
    "            # Normalize masked logits to form a proper log_softmax\n",
    "            output_final = F.log_softmax(masked_logits, dim=1)\n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            criterion = criterion.to(device)\n",
    "            \n",
    "            loss_reduced = criterion(output_reduced, target_reduced)\n",
    "            loss_final = criterion(output_final, y)\n",
    "            izy = math.log(10, 2) - F.nll_loss(output_final, y).div(math.log(2))\n",
    "            #print(izy)\n",
    "            total_izy += izy.item()  # Accumulate the izy value\n",
    "            #izx is KL given the VIB derivation\n",
    "            total_izx +=  KL.item()  \n",
    "            loss = loss_reduced + loss_final + beta * KL\n",
    "            loss = -izy + beta*KL\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                raise Exception(\"NaN value\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "       # acc, pruned_number = test(epoch, noise=0.1)\n",
    "\n",
    "        #print('Test Accuracy:', acc, 'Pruned dim:', pruned_number, 'Activated dim:', intermediate_dim - pruned_number)\n",
    "        avg_izy = total_izy / num_batches\n",
    "        avg_izx = total_izx / num_batches\n",
    "\n",
    "        print(f\"Epoch {epoch} - Average izyreduced: , Average izy: {avg_izy}, Average izx: {avg_izx}\")\n",
    "\n",
    "    #     if epoch > 7:\n",
    "    #         if (acc > test_acc and pruned_number == pruned_dim) or pruned_number > pruned_dim:\n",
    "    #             test_acc = acc\n",
    "    #             pruned_dim = pruned_number\n",
    "    #             saved_model = copy.deepcopy(model.state_dict())\n",
    "    #             print('Best ckpt:', test_acc, 'pruned_number:', pruned_dim, 'beta:', beta)\n",
    "    #             torch.save({'model': saved_model}, './CIFAR_model.pth')\n",
    "    # print('Best Accuracy:', test_acc, 'Intermediate Dim:', intermediate_dim, 'Beta:', beta)\n",
    "    # torch.save({'model': saved_model}, './CIFAR_model_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def test(epoch, noise=0.1):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(test_loader_this): \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output_reduced, output_final_logits, _ = model(images, epoch, noise)\n",
    "            \n",
    "            # Get reduced labels\n",
    "            target_reduced = get_reduced_labels(labels)\n",
    "            \n",
    "            # Compute the final output based on the reduced label mask\n",
    "            batch_size = output_final_logits.size(0)\n",
    "            mask = model.mask_matrix[target_reduced]\n",
    "            masked_logits = output_final_logits * mask\n",
    "            \n",
    "            # Normalize masked logits to form a proper log_softmax\n",
    "            output_final = F.log_softmax(masked_logits, dim=1)\n",
    "            \n",
    "            # Evaluate based on the final output\n",
    "            _, predicted = torch.max(output_final.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        hard_mask, mu = model.get_mask_inference(torch.FloatTensor([noise]).to(device))\n",
    "        index = torch.nonzero(torch.lt(hard_mask, 0.5)).squeeze(1)\n",
    "        pruned_number = index.size()[0]\n",
    "        return 100 * correct / total, pruned_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:0\n",
      "tensor(-0.5268, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(1.6985, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(0.8777, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.0607, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.0875, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.2529, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3948, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4491, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4791, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4636, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5953, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5445, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3793, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4723, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5728, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4952, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3397, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4892, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5121, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.2937, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3356, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5738, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6054, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4868, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.2855, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4824, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4184, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5370, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5737, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.2909, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5580, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.1496, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4813, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4711, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5639, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.2140, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4522, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4462, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3625, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4340, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4639, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4209, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4538, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3751, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4596, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4188, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3439, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4506, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3027, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4432, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4524, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4724, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3983, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5841, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3825, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3983, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6073, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5031, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4521, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3749, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4786, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3865, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4361, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3222, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5622, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5027, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6588, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5314, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6571, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5249, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5053, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5457, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4239, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6648, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3800, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3222, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3312, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6937, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5111, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3820, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4412, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5158, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4452, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3342, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6320, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.2774, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5583, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.2743, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3624, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5843, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5225, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5555, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4734, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5894, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5683, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6023, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5131, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4857, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5900, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5680, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4879, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6344, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5594, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5031, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4655, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6156, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5603, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4747, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4808, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4653, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4511, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5233, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5916, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5060, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6600, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5783, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6246, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4858, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4317, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5497, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5508, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3373, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4915, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6579, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5790, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4585, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4854, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4895, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5721, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4949, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3208, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5111, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5568, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.2728, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4905, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4132, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4449, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4951, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5658, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4765, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5492, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4675, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5821, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5106, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4817, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3632, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5444, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5541, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3849, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3921, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5123, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4898, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4975, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6273, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5497, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3812, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5741, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6347, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5615, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5331, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4731, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5558, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4957, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5470, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5383, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6355, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5254, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5554, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4502, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5285, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4976, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4833, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4763, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4205, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4583, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5300, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4685, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5151, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5210, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5438, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4953, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5501, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5687, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5368, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.2695, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4027, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6132, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5550, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5146, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.2755, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4291, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5538, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6282, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6392, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5560, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4857, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5260, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6177, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5268, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4866, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5231, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4918, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6244, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4783, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5848, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5012, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5101, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5363, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4898, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6343, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5840, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5463, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5493, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4982, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4501, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6048, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6002, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5449, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4705, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3985, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7074, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6931, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4747, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4486, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3327, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7187, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6219, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6234, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4298, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5317, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4880, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7032, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3210, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6046, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5252, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5778, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7270, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6673, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6458, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5353, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5841, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5455, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3870, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4221, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4071, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6155, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5545, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4158, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5656, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6405, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5619, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4898, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5725, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5264, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6440, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5527, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6255, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6462, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6515, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3407, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5970, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4489, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5280, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6295, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5524, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5703, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6217, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4903, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4671, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4266, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5802, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4540, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6565, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5745, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6382, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5652, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6886, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5052, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6550, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6199, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5894, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6501, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5534, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5287, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5388, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6154, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5415, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5635, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4276, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4166, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5295, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5017, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5581, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3482, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4523, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5391, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6396, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4945, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5171, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5779, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6835, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5911, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5458, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6316, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6253, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5664, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5067, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6730, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5731, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5611, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5077, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5854, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6156, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6567, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6768, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6520, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6034, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6200, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6060, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5673, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6111, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6447, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6348, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6436, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6974, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6964, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5946, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6474, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6928, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7356, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4979, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5729, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5216, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7166, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5351, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6325, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6096, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7020, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6426, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7015, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4785, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6851, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5838, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6069, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4048, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5418, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6347, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5855, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5302, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3549, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4281, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5395, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6563, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4650, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4204, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6334, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6082, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5585, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5598, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4800, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4233, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5559, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4735, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5694, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4884, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6551, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6719, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5395, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7084, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6190, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6383, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6261, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5711, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5105, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6775, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6555, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5609, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5685, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6031, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6910, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7144, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6316, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6315, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6334, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6863, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6330, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7031, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6900, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7584, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 0 - Average izyreduced: , Average izy: 2.5122665615033006, Average izx: 37.85386487712031\n",
      "\n",
      "epoch:1\n",
      "tensor(2.6324, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6109, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5507, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6189, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6723, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6410, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7092, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5010, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5939, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7050, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6657, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6885, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5614, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5229, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5770, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6756, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5580, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5659, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6488, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6663, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6317, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6432, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6651, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5757, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6368, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5476, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7416, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6526, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6965, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7410, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5768, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6010, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6969, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5821, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7281, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5754, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6325, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6528, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6990, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5247, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5775, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7440, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6382, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7620, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6867, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6675, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6631, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5735, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7640, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5734, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7314, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5456, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6476, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6261, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6389, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4946, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5739, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7079, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6537, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5410, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6292, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6908, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6359, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6948, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6415, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7114, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6097, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6637, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7365, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6230, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6131, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7905, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6645, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5087, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6096, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6685, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7657, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5384, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6763, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5773, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6033, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7092, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6014, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6479, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7152, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5783, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6410, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6914, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7967, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4300, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6747, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6487, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6596, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5772, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6611, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5891, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5780, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6787, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6269, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6739, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6322, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6970, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6499, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6625, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6816, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7076, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5888, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6692, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6938, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7130, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7347, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6525, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6283, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6319, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8251, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7604, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6552, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7577, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7534, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6828, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8048, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8015, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6943, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5438, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6127, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5920, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7986, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6797, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6869, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5834, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7369, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6511, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6542, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7394, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6826, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7156, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6933, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7732, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6574, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5973, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7086, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8442, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7060, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7254, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6620, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6252, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6955, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8550, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6438, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7269, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8623, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8198, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8003, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6985, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6993, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8587, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8176, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6200, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8247, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6901, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8331, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4863, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7066, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4840, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6693, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7136, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7426, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6817, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5033, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7040, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5516, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6962, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7359, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6590, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6811, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7814, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5770, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7462, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7399, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6267, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7565, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6545, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8180, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7786, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5786, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7383, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6595, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7026, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7828, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5725, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6433, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6596, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7988, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5032, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7172, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6859, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7898, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6390, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6748, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6300, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5824, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6880, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8042, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6977, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7203, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5710, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6301, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8098, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7402, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7234, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8130, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8811, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7504, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6121, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8014, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6840, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6996, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7393, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7048, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7473, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6595, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8269, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6822, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7265, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7555, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6373, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7837, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6714, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6186, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7552, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6305, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.3387, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7257, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8695, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6249, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4773, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4939, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6447, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7690, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7063, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6480, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7722, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7157, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7501, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5574, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7014, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6938, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7602, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8542, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7842, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7607, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7332, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7617, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7406, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4554, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8757, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7800, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5829, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6466, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6383, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7312, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8729, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7552, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7740, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8244, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8119, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6878, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7490, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6946, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8242, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7043, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4170, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7508, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7020, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7610, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7219, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6291, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7938, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6842, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7995, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7745, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7392, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7206, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6746, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7141, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6009, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7320, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6952, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7225, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8219, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7510, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6857, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6708, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8139, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7403, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6516, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7817, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8757, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7867, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4937, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7371, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8662, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7392, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7698, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7838, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6879, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6227, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7610, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7731, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7869, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7337, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6752, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7961, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7087, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7252, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7559, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7311, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6020, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6285, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6508, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7072, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5357, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.5323, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6540, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7413, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8374, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7130, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6144, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.4162, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6831, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6744, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7506, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7970, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7206, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7250, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7273, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8293, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8305, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7548, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6148, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8614, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7827, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7234, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7436, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8191, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7562, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7766, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7438, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7928, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8952, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.9162, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6744, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8294, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7126, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8209, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8254, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7478, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7927, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8019, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6391, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8185, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8594, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8195, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8253, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7933, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8118, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8247, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7466, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7160, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7524, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8897, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6352, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6119, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7099, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7400, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8159, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6120, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7954, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8032, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.6293, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8085, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8394, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7429, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7188, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7524, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8020, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7738, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7796, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8400, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.8146, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "tensor(2.7337, device='cuda:0', grad_fn=<RsubBackward1>)\n",
      "Epoch 1 - Average izyreduced: , Average izy: 5.208639854665303, Average izx: 53.87650419440111\n",
      "\n",
      "epoch:2\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 98: character maps to <undefined>. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "channel_noise_arg = 0.5\n",
    "weights = 'VL-VFE/CIFAR-model.pth'\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load(weights)['model'])\n",
    "accuracy = 0\n",
    "t = 20\n",
    "for i in range (t):\n",
    "    acc, pruned_number = test(0,channel_noise_arg)\n",
    "    accuracy += acc\n",
    "#print('Noise level:',args.channel_noise,'Test Accuracy:',accuracy/t,'Activated dim:', args.intermediate_dim - pruned_number)\n",
    "print('Noise level:',channel_noise_arg, 'Test Accuracy:', accuracy/t, 'Pruned dim:', pruned_number, 'Activated dim:', intermediate_dim - pruned_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
